---
title: "Week 3 Tutorial Exercises"
author: "Amy Perfors"
output: html_document
---

We've seen from Bunny and Gladly's surveys so far a kind of weird and maybe interesting thing: when asked to rate how much they'd want to eat various items right now, all of the ratings were very high, with averages and means well above 5 on a 10-point scale and very few ratings below 5 at all. We know it's not because people just don't understand the questions, because the ratings for questions about non-food items like mud are exactly where you'd expect: around 1 or 2.

So... what's going on? 

"I think it's just that food is very yummy and people like to eat all of the time," says Gladly.

"That doesn't make sense though," says Shadow. "Surely they would rate things pretty low after they've just eaten dinner?"

"That's a good idea," says Doggie. "Maybe you asked all of the questions right before dinner or something, Gladly."

"No," says Gladly. I usually asked them right after breakfast in fact, because that's when everybody is easy to find."

"I'm worried," says Bunny. 

"Yeah," says Flopsy. "What if we don't have enough food? What if everybody is starving?"

"Oh calm down, Bunny," Doggie says, irritated. (He is often irritated by Bunny's anxiety, and not very good at hiding it). "Don't you think we'd realise if we were starving?"

"Well... I *am* hungry all of the time," says Gladly.

"Of course you are, you're a bear!"

"Please stop bickering," Bunny says miserably. "It makes me sad."

Everyone is quiet for a moment, and then Shadow says, "Hey, I have an idea! We can use data to figure this out."

"Where can we get more data?" asks Flopsy. "It's not like it's just lying on the ground."

"I just remembered that LFB and Black have been doing a yearly survey on just this question," Shadow says.

"Oh yeah that's right!" says Gladly. "That's where I got the idea for the questions in the first place."

"So let's ask them for their data. We can see if anything has changed over time. Also I think they asked about more foods, so we can see if it's about that."

The friends all agree that that was a great idea, and get that dataset. In this tutorial activity you'll use your skills to analyse it and see if you can figure out what is going on. Are the bunnies and friends slowly starving to death, or just bad at using the scales on this survey? Has anything changed over time? These are the questions for today.

# Q1

First, load the libraries and data you'll need. I've filled in some of the libraries but you may find as you go through that you need to add them here. The dataset is called `shadowsurvey.csv` and it can be found in this folder, assuming you didn't move anything when you downloaded from Canvas.

```{r setup, include=FALSE}
# We'll begin by loading up the libraries and data we need, as always.
knitr::opts_chunk$set(echo = TRUE)

# loading the libraries
library(tidyverse)
library(knitr)
library(here)
library(skimr)
library(lsr)
# you'll need to add a few more libraries as you go

# ** you need to load the data using the here() function, as in the example in class
loc <- here("shadowsurvey.csv")
d <- read_csv(file=loc)
```

## Description of the dataset

This dataset is very much like Gladly's which we've spent so much time in lecture on, except that Shadow has been collecting this data for five years (since 2016) and also asked about more foods than Gladly did. The columns in the dataset `d` are:

*name*: name of the person

*gender*: their reported gender

*species*: their species

*year*: the year the question was asked

*carrot,bean,cake,meat,mud,dirt*: questions about how much the person in question wanted to each of these items when asked


# Q2

Let's first get a sense of the dataset. Use the `skim` command to do so. Note: you may have to load the appropriate library first.


```{r skimdatachunk, echo=FALSE}
# insert your code here
skim(d)
```

# Q3

It's really annoying to have all six of these survey questions when really there are only two main distinctions we want to make: between the foods we expect people to rate highly (carrot, cake, bean, and meat) and the things that aren't food at all and we expect them to rate low (mud, dirt). To that end, make two new variables in `d` called `goodFood` and `badFood`. `goodFood` should be the mean of the responses to the four foods and `badFood` should be the mean of the responses to mud and dirt. Note: you can either do this using the techniques discussed on Day 1 in Week 2, or if you've already seen the videos for Day 2 in Week 3, using the `mutate` operator.

```{r makenewvarschunk, echo=FALSE}
# insert your code here
goodFoods <- c("carrot", "cake", "bean", "meat")
badFoods <- c("mud", "dirt")
d$goodFood <- apply(d[,goodFoods], MARGIN = 1,FUN = mean)
# the above works -- the below doesn't.... not sure why lol.
#d$goodFood <- mean(d[,goodFoods])
d$badFood <- apply(d[,badFoods], MARGIN = 1,FUN = mean)
 d[,goodFoods]
d[c("name","goodFood", "badFood")]
```

# Q4

Make your own histogram for the two new variables you've made (goodFood and badFood). Make sure you have a clear title for each, and if you want to, set a different colour for each too. What do these histograms show you?

```{r histogramchunk, echo=FALSE}
 #partition the graphics device, 2stacked
par(mfrow = c(2, 1))
# calculated a common max and min to allow horizontal alignment
# then make 2 histograms (that code seems pretty self-explanatory)
#  stolen from https://stackoverflow.com/questions/19375779/how-to-set-xlim-in-a-hist-plot-while-showing-the-full-range-of-the-variable-in
xrange <- range( c(d[["goodFood"]], d[["badFood"]]) )
xrange
# so here i was  using mode but should have used max freq from lsr
# idiot but hey
# yrange <- range( c(0, mode( c(d[["goodFood"]],d[["badFood"]]) )))
# let's work out the max freq so both plots have same vertical scale

yrange <- range( c(0, maxFreq( c(d[["goodFood"]],d[["badFood"]]), na.rm = TRUE )))
#mode(c(d[["goodFood"]], d[["badFood"]]), rm.na = TRUE)
yrange
hist(
  x = d[["goodFood"]], breaks = "Sturges",
  freq = TRUE, 
  include.lowest = TRUE, right = TRUE,
  density = 20, angle = 45, col = "blue", border = NULL,
  main = "Frequency histogram of Good Foods",
  xlim = xrange, ylim = yrange,
   xlab = "Rating", ylab = "Frequency",
   #  axes = TRUE, plot = TRUE, labels = FALSE,
  #   nclass = NULL, warn.unused = TRUE
)
hist(
  x = d[["badFood"]], breaks = "Sturges",
  freq = TRUE, 
  include.lowest = TRUE, right = TRUE,
  density = 20, angle = 45, col = "blue", border = NULL,
  main = "Frequency histogram of Bad Foods",
  xlim = xrange, ylim = yrange,
     xlab = "Rating", ylab = "Frequency",
   #  axes = TRUE, plot = TRUE, labels = FALSE,
  #   nclass = NULL, warn.unused = TRUE
)
#hist(
#  x = d[["badFood"]]
#)

```


# Q5

Calculate the mean, median, mode, and 10th and 90th quantile of `goodFood` and `badFood`. Don't use `skim()`, use the functions for each. (Note: you may need to load another library). Do these numbers make sense in light of the histograms?

```{r centraltendencychunk}

my_descriptives<- function(data, summary_var) {
  summary_var <- enquo(summary_var)
  data %>% 
    summarise(#column = colnames(UQ(summary_var)),
      mean = mean(!!summary_var), 
              median = median(!!summary_var), 
              mode = modeOf(!!summary_var), 
              "10th" = quantile(!!summary_var, probs = .1), 
              "90th" = quantile(!!summary_var, probs = .9))
}

#my_descriptives(d, goodFood)

# but i cant get a) the column names or b) do more than one column
# lets do this old-school

mysummary <- function(x) {
 result <- list(
   mean(x, na.rm = TRUE),
   median(x, na.rm = TRUE),
   modeOf(x, na.rm = TRUE),
   quantile(x, probs = .1, na.rm = TRUE),
   quantile(x, probs = .9, na.rm = TRUE))
 names(result) <- c("Mean", "Median", "Mode", "10% QT", "90% QT")
 return(as.vector(result))
}


# So I wanted to make a table of these in a function but giving up now haha
# i was defeated 

food_opinions <- c("goodFood", "badFood")
sumdf <- lapply(d[food_opinions], mysummary)
sumdf

str(sumdf$goodFood)

#sumdf %>%
#  gather(var, val, 2:ncol(sumdf)) %>%
#  spread(var, val)
#c(mean(),median(), modeOf(), quantile(probs = .1), quantile(probs = .9))

# ok lets do this
d %>%
  summarise(
       mysummary(goodFood),
 #      mysummary(badFood)
  )
```

# Q6

One of the different things about this dataset (compared to Gladly's) is that there is data from multiple years. So let's investigate it! Make a frequency table showing the number of data points for each year, and use the `kable()` function to make it look nice. How is it changing over time? Why do you suppose it is?

```{r yeartablechunk, echo=FALSE}

d %>%
  group_by(year) %>%
  summarise(
    n()
  ) %>%
  ungroup() %>%
  kable()

# haha realised you wanted me to use table()
# weird slightly tidyverse slightly oldschool code ugh
table(d$year) %>% kable(col.names = c("year", "frequency"))

  
```

# Q7

Let's get a breakdown of what species are represented each year. Make a table of species by year, and make it look nice using `kable()`. The columns should be the years and the rows the species.

```{r yearspecieschunk, echo=FALSE}
#first attempt
d %>%
group_by(year, species) %>%
  summarise(freq = n()) %>%
 pivot_wider(
   names_from = year,
   values_from = freq,
   values_fill = list(freq = 0)
  ) %>%
  ungroup() %>%
  kable()
#nope

#again i realise this is about table lol

  table(d$species, d$year) %>% kable()
```

# Q8

Let's first see if there are gender differences in how people answer the questions.

To look at this, use the `group_by()` and `summarise()` functions to group the data by gender and calculate the mean `goodFood` and mean `badFood` for each gender Remember to ungroup! What does your data seem to suggest?

```{r gendergroupchunk, echo=FALSE}
d %>%
  group_by(gender) %>%
  select(goodFood, badFood) %>%
  summarise("Good Food" = mean(goodFood),
            "Bad Food" = mean(badFood)
            ) %>%
  ungroup() %>%
  kable()
```

# Q9

Another interesting thing to look at would be how the answers to the questions change over time. To look at this, use the `group_by()` and `summarise()` functions to group the data by year and calculate the mean and sd for `goodFood`, the mean and sd for `badFood`, and the n for each year. Remember to ungroup! What does your data seem to suggest?

```{r yeargroupchunk, echo=FALSE}
d %>%
  group_by(year) %>%
  summarise(
   "Mean (goodFood)" = mean(goodFood),
  "SD (goodFood)" = sd(goodFood),
  "Mean (badFood)" = mean(badFood),
  "SD (badFood)" = sd(badFood),
  "n" = n(),
  ) %>%
  ungroup()
```

